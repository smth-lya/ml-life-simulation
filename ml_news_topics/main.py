from config.paths import RAW_DATA_PATH, PROCESSED_DATA_PATH
from utils.data_loader import load_articles
from utils.text_processor import process_text
from utils.vocabulary import build_vocab, save_vocab
from tqdm import tqdm
from colorama import init, Fore, Style
from NaiveBayesClassifier import NaiveBayesClassifier
import time
import json
import random
from collections import defaultdict

init(autoreset=True)

def split_data(articles, test_ratio=0.3, random_seed=None):
    """–†–∞–∑–¥–µ–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏"""
    if random_seed is not None:
        random.seed(random_seed)

    shuffled = articles.copy()
    random.shuffle(shuffled)

    split_idx = int(len(shuffled) * (1 - test_ratio))
    return shuffled[:split_idx], shuffled[split_idx:]

def print_header():
    print(Fore.CYAN + "=" * 50)
    print(Fore.YELLOW + "üöÄ –ù–û–í–û–°–¢–ù–û–ô –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† –ù–ê –ë–ê–ô–ï–°–ï".center(50))
    print(Fore.CYAN + "=" * 50 + Style.RESET_ALL)

def print_step(step, description):
    print(Fore.GREEN + f"\n[{step}] {description}" + Style.RESET_ALL)
    time.sleep(0.3)

def evaluate_model(classifier, test_articles):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
    print_step("5", "–û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏...")

    correct = 0
    total = len(test_articles)
    class_stats = defaultdict(lambda: {'correct': 0, 'total': 0})
    predictions = []

    # –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    for article in tqdm(test_articles, desc="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", unit="—Å—Ç–∞—Ç—å—è", colour='blue'):
        predictions.append(classifier.predict(article["short_description"]))

    # –ó–∞—Ç–µ–º –≤—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    for article, predicted in zip(test_articles, predictions):
        true_category = article["category"]
        class_stats[true_category]['total'] += 1
        if predicted == true_category:
            correct += 1
            class_stats[true_category]['correct'] += 1

    accuracy = correct / total

    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
    report = {
        'accuracy': accuracy,
        'class_metrics': {}
    }

    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
    pred_counts = defaultdict(int)
    for pred in predictions:
        pred_counts[pred] += 1

    for cat, stats in class_stats.items():
        preds_for_class = pred_counts.get(cat, 0)

        precision = stats['correct'] / preds_for_class if preds_for_class > 0 else 0
        recall = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

        report['class_metrics'][cat] = {
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'support': stats['total']
        }

    return report

def print_report(report):
    """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏"""
    print(Fore.CYAN + "\n" + "=" * 50)
    print(Fore.YELLOW + "üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–¶–ï–ù–ö–ò".center(50))
    print(Fore.CYAN + "=" * 50)

    print(Fore.LIGHTGREEN_EX + f"\n–û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {report['accuracy']:.2%}")

    print(Fore.LIGHTBLUE_EX + "\n–î–µ—Ç–∞–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    for cat, metrics in report['class_metrics'].items():
        print(f"{Fore.WHITE}{cat}: "
              f"Prec={metrics['precision']:.2f}, "
              f"Rec={metrics['recall']:.2f}, "
              f"F1={metrics['f1']:.2f} "
              f"(n={metrics['support']})")

def main():
    print_header()

    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print_step("1", "–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–µ–π...")
    articles = load_articles(RAW_DATA_PATH)
    print(Fore.LIGHTBLUE_EX + f"‚úî –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π" + Style.RESET_ALL)

    # 2. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    print_step("2", "–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test...")
    train_articles, test_articles = split_data(articles, test_ratio=0.3, random_seed=42)
    print(Fore.LIGHTBLUE_EX +
          f"‚úî –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(train_articles)} —Å—Ç–∞—Ç–µ–π\n"
          f"‚úî –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(test_articles)} —Å—Ç–∞—Ç–µ–π" +
          Style.RESET_ALL)

    # 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–ª–æ–≤–∞—Ä—è
    if PROCESSED_DATA_PATH.exists():
        print_step("3", "–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è...")
        with open(PROCESSED_DATA_PATH, 'r') as f:
            vocab = json.load(f)
        print(Fore.LIGHTBLUE_EX + f"‚úî –ó–∞–≥—Ä—É–∂–µ–Ω —Å–ª–æ–≤–∞—Ä—å ({len(vocab)} —Ç–æ–∫–µ–Ω–æ–≤)" + Style.RESET_ALL)
    else:
        print_step("3", "–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è...")
        all_tokens = []
        for article in tqdm(train_articles, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞", unit="—Å—Ç–∞—Ç—å—è", colour='green'):
            tokens = process_text(article.get("headline", "") + " " + article.get("short_description", ""))
            all_tokens.extend(tokens)

        vocab = build_vocab(all_tokens)
        save_vocab(vocab, PROCESSED_DATA_PATH)
        print(Fore.LIGHTBLUE_EX + f"‚úî –°–æ–∑–¥–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –Ω–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å ({len(vocab)} —Ç–æ–∫–µ–Ω–æ–≤)" + Style.RESET_ALL)

    # 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print_step("4", "–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    classifier = NaiveBayesClassifier(vocab)
    classifier.train(train_articles)
    print(Fore.LIGHTBLUE_EX + f"‚úî –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ {len(train_articles)} —Å—Ç–∞—Ç—å—è—Ö" + Style.RESET_ALL)

    # 5. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
    report = evaluate_model(classifier, test_articles)
    print_report(report)

    # 6. –î–µ–º–æ-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    test_text = "Cleaner Was Dead In Belk Bathroom For 4 Days Before Body Found"
    predicted_category = classifier.predict(test_text)

    print(Fore.CYAN + "\n" + "=" * 50)
    print(Fore.YELLOW + f"üì∞ –î–ï–ú–û-–ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï".center(50))
    print(Fore.CYAN + "=" * 50)
    print(Fore.LIGHTWHITE_EX + f"\n–¢–µ–∫—Å—Ç: {test_text}")
    print(Fore.LIGHTGREEN_EX + f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {predicted_category}" + Style.RESET_ALL)

if __name__ == '__main__':
    main()